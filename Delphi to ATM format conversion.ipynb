{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Delphi to ATM format conversion\n",
    "\n",
    "## Overview\n",
    "\n",
    "This notebook loads the old Delphi CSVs and transforms them creating some new columns, renaming some of the old ones and resorting them to match the current ATM Modelhub format.\n",
    "\n",
    "### Warning\n",
    "\n",
    "Some columns are renamed to match the current ATM names but their data format still does not match the new one.\n",
    "\n",
    "This happens for all the Base64 encoded columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration\n",
    "\n",
    "The notebook has several options which are configured in the cell below.\n",
    "These are:\n",
    "\n",
    "* EMPTY_NEW_COLUMNS: If **True**, any column that did not exist in Delphi but exists in ATM will created with empty data. If **False**, this will be skipped and no new columns will be created.\n",
    "* READ_BUCKET: If provided, the CSVs will be downloaded from the given S3 bucket. If empty, they will be read from local folder.\n",
    "* WRITE_BUCKET: If provided, the CSVs will be uploaded to the given S3 bucket. Otherwise they will be saved in a local folder.\n",
    "* READ_PATH: Folfer to read the CSVs from.\n",
    "* WRITE_PATH: Folder to write the CSVs to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMPTY_NEW_COLUMNS = False\n",
    "READ_BUCKET = 'atm-data-store'\n",
    "READ_PATH = 'gp+bandit-search/csvs/'\n",
    "WRITE_BUCKET = 'atm-data-store'\n",
    "WRITE_PATH = 'gp+bandit-search/csvs/new/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import os\n",
    "\n",
    "import boto3\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if READ_BUCKET:\n",
    "    read_bucket = boto3.resource('s3').Bucket(READ_BUCKET)\n",
    "    \n",
    "if WRITE_BUCKET:\n",
    "    write_bucket = boto3.resource('s3').Bucket(WRITE_BUCKET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv(name, *args, **kwargs):\n",
    "    path = os.path.join(READ_PATH, name)\n",
    "    if READ_BUCKET:\n",
    "        print('Downloading file {} from S3 bucket {}'.format(path, read_bucket))\n",
    "        body = read_bucket.Object(path).get()['Body'].read()\n",
    "        with io.BytesIO(body) as buf:\n",
    "            return pd.read_csv(buf, *args, **kwargs)\n",
    "        \n",
    "    else:\n",
    "        return pd.read_csv(path, *args, **kwargs)\n",
    "\n",
    "def to_csv(df, name, *args, **kwargs):\n",
    "    path = os.path.join(WRITE_PATH, name)\n",
    "    if WRITE_BUCKET:\n",
    "        print('Uploading file {} to S3 bucket {}'.format(path, write_bucket))\n",
    "        with io.StringIO() as buf:\n",
    "            df.to_csv(buf, *args, **kwargs)\n",
    "            write_bucket.Object(path).put(Body=buf.getvalue())\n",
    "            \n",
    "    else:\n",
    "        df.to_csv(path, *args, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets\n",
    "\n",
    "A Dataset represents a single set of data which can be used to train and test models by ATM. The table stores information about the location of the data as well as metadata to help with analysis.\n",
    "\n",
    "* id (Int): Unique identifier for the dataset.\n",
    "* name (String): Identifier string for a classification technique.\n",
    "* class_column (String): Name of the class label column.\n",
    "* train_path (String): Location of the dataset train file.\n",
    "* test_path (String): Location of the dataset test file.\n",
    "* description (String): Human-readable description of the dataset.\n",
    "   * not described in the paper\n",
    "\n",
    "The metadata fields below are not described in the paper.\n",
    "\n",
    "* n_examples (Int): Number of samples (rows) in the dataset.\n",
    "* k_classes (Int): Number of classes in the dataset.\n",
    "* d_features (Int): Number of features in the dataset.\n",
    "* majority (Number): Ratio of the number of samples in the largest class to the number of samples in all other classes.\n",
    "* size_kb (Int): Approximate size of the dataset in KB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading file gp+bandit-search/csvs/datasets.csv from S3 bucket s3.Bucket(name='atm-data-store')\n"
     ]
    }
   ],
   "source": [
    "datasets = read_csv('datasets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets['id'] = datasets['dataset_id']\n",
    "\n",
    "if EMPTY_NEW_COLUMNS:\n",
    "    datasets['description'] = None\n",
    "    datasets['n_examples'] = None\n",
    "    datasets['k_classes'] = None\n",
    "    datasets['d_features'] = None\n",
    "    datasets['majority'] = None\n",
    "    datasets['size_kb'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_columns = ['id', 'name', 'class_column', 'train_path', 'test_path']\n",
    "\n",
    "if EMPTY_NEW_COLUMNS:\n",
    "    dataset_columns += ['description', 'n_examples', 'k_classes', 'd_features', 'majority','size_kb']\n",
    "    \n",
    "datasets = datasets[datasets_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>name</th>\n",
       "      <td>2dplanes_1</td>\n",
       "      <td>AP_Endometrium_Prostate_1</td>\n",
       "      <td>Amazon_employee_access_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class_column</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_path</th>\n",
       "      <td>data/processed/2dplanes_1_train.csv</td>\n",
       "      <td>data/processed/AP_Endometrium_Prostate_1_train...</td>\n",
       "      <td>data/processed/Amazon_employee_access_1_train.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_path</th>\n",
       "      <td>data/processed/2dplanes_1_test.csv</td>\n",
       "      <td>data/processed/AP_Endometrium_Prostate_1_test.csv</td>\n",
       "      <td>data/processed/Amazon_employee_access_1_test.csv</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                0  \\\n",
       "id                                              1   \n",
       "name                                   2dplanes_1   \n",
       "class_column                                    0   \n",
       "train_path    data/processed/2dplanes_1_train.csv   \n",
       "test_path      data/processed/2dplanes_1_test.csv   \n",
       "\n",
       "                                                              1  \\\n",
       "id                                                            2   \n",
       "name                                  AP_Endometrium_Prostate_1   \n",
       "class_column                                                  0   \n",
       "train_path    data/processed/AP_Endometrium_Prostate_1_train...   \n",
       "test_path     data/processed/AP_Endometrium_Prostate_1_test.csv   \n",
       "\n",
       "                                                              2  \n",
       "id                                                            3  \n",
       "name                                   Amazon_employee_access_1  \n",
       "class_column                                                  0  \n",
       "train_path    data/processed/Amazon_employee_access_1_train.csv  \n",
       "test_path      data/processed/Amazon_employee_access_1_test.csv  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets.head(3).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading file gp+bandit-search/csvs/new/datasets.csv to S3 bucket s3.Bucket(name='atm-data-store')\n"
     ]
    }
   ],
   "source": [
    "to_csv(datasets, 'datasets.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataruns\n",
    "\n",
    "A Datarun is a single logical job for ATM to complete. The Dataruns table contains a reference to a dataset, configuration for ATM and BTB, and state information.\n",
    "\n",
    "* id (Int): Unique identifier for the datarun.\n",
    "* dataset_id (Int): ID of the dataset associated with this datarun.\n",
    "* description (String): Human-readable description of the datarun.\n",
    "    * not in the paper\n",
    "\n",
    "BTB configuration:\n",
    "\n",
    "* selector (String): Selection technique for hyperpartitions.\n",
    "  * called “hyperpartition_selection_scheme” in the paper\n",
    "* k_window (Int): The number of previous classifiers the selector will consider, for selection techniques that set a limit of the number of historical runs to use.\n",
    "  * called “ts” in the paper\n",
    "* tuner (String): The technique that BTB will use to choose new continuous hyperparameters.\n",
    "  * called “hyperparameters_tuning_scheme” in the paper\n",
    "* r_minimum (Int): The number of random runs that must be performed in each hyperpartition before allowing Bayesian optimization to select parameters.\n",
    "* gridding (Int): If this value is set to a positive integer, each numeric hyperparameter will be chosen from a set of gridding discrete, evenly-spaced values. If set to 0 or NULL, values will be chosen from the full, continuous space of possibilities.\n",
    "  * not in the paper\n",
    "\n",
    "ATM configuration:\n",
    "\n",
    "* priority (Int): Run priority for the datarun. If multiple unfinished dataruns are in the ModelHub at once, workers will process higher-priority runs first.\n",
    "* budget_type (Enum): One of [“learner”, “walltime”]. If this is “learner”, only budget classifiers will be trained; if “walltime”, classifiers will only be trained for budget minutes total.\n",
    "* budget (Int): The maximum number of classifiers to build, or the maximum amount of time to train classifiers (in minutes).\n",
    "  * called “budget_amount” in the paper\n",
    "* deadline (DateTime): If provided, and if budget_type is set to “walltime”, the datarun will run until this absolute time. This overrides the budget column.\n",
    "  * not in the paper\n",
    "* metric (String): The metric by which to score each classifier for comparison purposes. Can be one of [“accuracy”, “cohen_kappa”, “f1”, “roc_auc”, “ap”, “mcc”] for binary problems, or [“accuracy”, “rank_accuracy”, “cohen_kappa”, “f1_micro”, “f1_macro”, “roc_auc_micro”, “roc_auc_macro”] for multiclass problems\n",
    "  * not in the paper\n",
    "* score_target (Enum): One of [“cv”, “test”, “mu_sigma”]. Determines how the final comparative metric (the judgment metric) is calculated.\n",
    "   * “cv” (cross-validation): the judgment metric is the average of a 5-fold cross-validation test.\n",
    "   * “test”: the judgment metric is computed on the test data.\n",
    "   * “mu_sigma”: the judgment metric is the lower error bound on the mean CV score.\n",
    "     * not in the paper\n",
    "\n",
    "State information:\n",
    "\n",
    "* start_time (DateTime): Time the DataRun began.\n",
    "* end_time (DateTime): Time the DataRun was completed.\n",
    "* status (Enum): Indicates whether the run is pending, in progress, or has been finished. One of [“pending”, “running”, “complete”].\n",
    "  * not in the paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading file gp+bandit-search/csvs/dataruns.csv from S3 bucket s3.Bucket(name='atm-data-store')\n"
     ]
    }
   ],
   "source": [
    "dataruns = read_csv('dataruns.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataruns['id'] = dataruns['datarun_id']\n",
    "dataruns['selector'] = dataruns['hyperpartition_selection_scheme']\n",
    "dataruns['k_window'] = dataruns['t_s']\n",
    "dataruns['tuner'] = dataruns['hyperparameter_tuning_scheme']\n",
    "dataruns['budget'] = dataruns['budget_amount']\n",
    "\n",
    "if EMPTY_NEW_COLUMNS:\n",
    "    dataruns['description'] = None\n",
    "    dataruns['gridding'] = None\n",
    "    dataruns['deadline'] = None\n",
    "    dataruns['metric'] = None\n",
    "    dataruns['score_target'] = None\n",
    "    dataruns['status'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "if EMPTY_NEW_COLUMNS:\n",
    "    dataruns_columns = [\n",
    "        'id', 'dataset_id', 'description', 'priority', 'selector',\n",
    "        'k_window', 'tuner', 'gridding', 'r_minimum', 'budget_type',\n",
    "        'budget', 'deadline', 'metric', 'score_target', 'start_time',\n",
    "        'end_time', 'status'\n",
    "    ]\n",
    "    \n",
    "else:\n",
    "    dataruns_columns = [\n",
    "        'id', 'dataset_id', 'priority', 'selector',\n",
    "        'k_window', 'tuner', 'r_minimum', 'budget_type',\n",
    "        'budget', 'start_time', 'end_time'\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataruns = dataruns[dataruns_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dataset_id</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>priority</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>selector</th>\n",
       "      <td>bestkvel</td>\n",
       "      <td>bestkvel</td>\n",
       "      <td>bestkvel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>k_window</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tuner</th>\n",
       "      <td>gp_ei</td>\n",
       "      <td>gp_ei</td>\n",
       "      <td>gp_ei</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r_minimum</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>budget_type</th>\n",
       "      <td>learner</td>\n",
       "      <td>learner</td>\n",
       "      <td>learner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>budget</th>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>start_time</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>end_time</th>\n",
       "      <td>2017-08-19 07:28:45</td>\n",
       "      <td>2017-08-19 08:42:06</td>\n",
       "      <td>2017-08-19 11:29:10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               0                    1                    2\n",
       "id                             1                    2                    3\n",
       "dataset_id                     1                    2                    3\n",
       "priority                      10                   10                   10\n",
       "selector                bestkvel             bestkvel             bestkvel\n",
       "k_window                       2                    2                    2\n",
       "tuner                      gp_ei                gp_ei                gp_ei\n",
       "r_minimum                      2                    2                    2\n",
       "budget_type              learner              learner              learner\n",
       "budget                       100                  100                  100\n",
       "start_time                   NaN                  NaN                  NaN\n",
       "end_time     2017-08-19 07:28:45  2017-08-19 08:42:06  2017-08-19 11:29:10"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataruns.head(3).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading file gp+bandit-search/csvs/new/dataruns.csv to S3 bucket s3.Bucket(name='atm-data-store')\n"
     ]
    }
   ],
   "source": [
    "to_csv(dataruns, 'dataruns.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperpartitions\n",
    "\n",
    "A Hyperpartition is a fixed set of categorical hyperparameters which defines a space of numeric hyperparameters that can be explored by a tuner. ATM uses BTB selectors to choose among hyperpartitions during a run. Each hyperpartition instance must be associated with a single datarun; the performance of a hyperpartition in a previous datarun is assumed to have no bearing on its performance in the future.\n",
    "\n",
    "* id (Int): Unique identifier for the hyperparition.\n",
    "* datarun_id (Int): ID of the datarun associated with this hyperpartition.\n",
    "* method (String): Code for, or path to a JSON file describing, this hyperpartition’s classification method (e.g. “svm”, “knn”).\n",
    "* categorical_hyperparameters_64 (Base64-encoded object): List of categorical hyperparameters whose values are fixed to define this hyperpartition.\n",
    "  * called “partition_hyperparameter_values” in the paper\n",
    "* tunable_hyperparameters_64 (Base64-encoded object): List of continuous hyperparameters which are free; their values must be selected by a Tuner.\n",
    "  * called “conditional_hyperparameters” in the paper\n",
    "* constant_hyperparameters_64 (Base64-encoded object): List of categorical or continuous parameters whose values are always fixed. These do not define the hyperpartition, but their values must be passed to the classification method to fully parameterize it.\n",
    "  * not in the paper\n",
    "* status (Enum): Indicates whether the hyperpartition has caused too many classifiers to error, or whether the grid for this partition has been fully explored. One of [“incomplete”, “gridding_done”, “errored”].\n",
    "  * not in the paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading file gp+bandit-search/csvs/hyperpartitions.csv from S3 bucket s3.Bucket(name='atm-data-store')\n"
     ]
    }
   ],
   "source": [
    "hyperpartitions = read_csv('hyperpartitions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperpartitions['id'] = hyperpartitions['hyperpartition_id']\n",
    "hyperpartitions['categorical_hyperparameters_64'] = hyperpartitions['partition_hyperparameter_values']\n",
    "hyperpartitions['tunable_hyperparameters_64'] = hyperpartitions['conditional_hyperparameters']\n",
    "\n",
    "if EMPTY_NEW_COLUMNS:\n",
    "    hyperpartitions['constant_hyperparameters_64'] = None\n",
    "    hyperpartitions['status'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperpartitions_columns = [\n",
    "    'id', 'datarun_id', 'method', 'categorical_hyperparameters_64',\n",
    "    'tunable_hyperparameters_64'\n",
    "]\n",
    "\n",
    "if EMPTY_NEW_COLUMNS:\n",
    "    hyperpartitions_columns += ['constant_hyperparameters_64', 'status']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperpartitions = hyperpartitions[hyperpartitions_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datarun_id</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>method</th>\n",
       "      <td>classify_rf</td>\n",
       "      <td>classify_rf</td>\n",
       "      <td>classify_dt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>categorical_hyperparameters_64</th>\n",
       "      <td>n_estimators:1000;criterion:entropy;</td>\n",
       "      <td>n_estimators:1000;criterion:gini;</td>\n",
       "      <td>criterion:entropy;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tunable_hyperparameters_64</th>\n",
       "      <td>min_samples_leaf:(1, 2):INT:NOCAT;max_features...</td>\n",
       "      <td>min_samples_leaf:(1, 2):INT:NOCAT;max_features...</td>\n",
       "      <td>min_samples_split:(2, 4):INT:NOCAT;max_feature...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                0  \\\n",
       "id                                                                              1   \n",
       "datarun_id                                                                      1   \n",
       "method                                                                classify_rf   \n",
       "categorical_hyperparameters_64               n_estimators:1000;criterion:entropy;   \n",
       "tunable_hyperparameters_64      min_samples_leaf:(1, 2):INT:NOCAT;max_features...   \n",
       "\n",
       "                                                                                1  \\\n",
       "id                                                                              2   \n",
       "datarun_id                                                                      1   \n",
       "method                                                                classify_rf   \n",
       "categorical_hyperparameters_64                  n_estimators:1000;criterion:gini;   \n",
       "tunable_hyperparameters_64      min_samples_leaf:(1, 2):INT:NOCAT;max_features...   \n",
       "\n",
       "                                                                                2  \n",
       "id                                                                              3  \n",
       "datarun_id                                                                      1  \n",
       "method                                                                classify_dt  \n",
       "categorical_hyperparameters_64                                 criterion:entropy;  \n",
       "tunable_hyperparameters_64      min_samples_split:(2, 4):INT:NOCAT;max_feature...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyperpartitions.head(3).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading file gp+bandit-search/csvs/new/hyperpartitions.csv to S3 bucket s3.Bucket(name='atm-data-store')\n"
     ]
    }
   ],
   "source": [
    "to_csv(hyperpartitions, 'hyperpartitions.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifiers\n",
    "\n",
    "A Classifier represents a single train/test run using a method and a set of hyperparameters with a particular dataset.\n",
    "\n",
    "* id (Int): Unique identifier for the classifier.\n",
    "* datarun_id (Int): ID of the datarun associated with this classifier.\n",
    "* hyperpartition_id (Int): ID of the hyperpartition associated with this classifier.\n",
    "* host (String): IP address or name of the host machine where the classifier was tested.\n",
    "    * not in the paper\n",
    "* model_location (String): Path to the serialized model object for this classifier.\n",
    "* metrics_location (String): Path to the full set of metrics computed during testing.\n",
    "* cv_judgment_metric (Number): Mean of the judgement metrics from the cross-validated training data.\n",
    "* cv_judgment_metric_stdev (Number): Standard deviation of the cross-validation test.\n",
    "* test_judgment_metric (Number): Judgment metric computed on the test data.\n",
    "* hyperparameter_values_64 (Base64-encoded object): The full set of hyperparameter values used to create this classifier.\n",
    "* start_time (DateTime): Time that a worker started working on the classifier.\n",
    "* end_time (DateTime): Time that a worker finished working on the classifier.\n",
    "* status (Enum): One of [“running”, “errored”, “complete”].\n",
    "* error_message (String): If this classifier encountered an error, this is the Python stack trace from the caught exception."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading file gp+bandit-search/csvs/classifiers.csv from S3 bucket s3.Bucket(name='atm-data-store')\n"
     ]
    }
   ],
   "source": [
    "classifiers = read_csv('classifiers.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers['id'] = classifiers['classifier_id']\n",
    "classifiers['hyperparameter_values_64'] = classifiers['hyperparameter_values']\n",
    "\n",
    "if EMPTY_NEW_COLUMNS:\n",
    "    classifiers['host'] = None\n",
    "    classifiers['cv_judgment_metric_stdev'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "if EMPTY_NEW_COLUMNS:\n",
    "    classifiers_columns = [\n",
    "        'id', 'datarun_id', 'hyperpartition_id', 'host', 'model_location',\n",
    "        'metrics_location', 'hyperparameter_values_64', 'cv_judgment_metric',\n",
    "        'cv_judgment_metric_stdev', 'test_judgment_metric', 'start_time',\n",
    "        'end_time', 'status', 'error_message',\n",
    "    ]\n",
    "\n",
    "else:\n",
    "    classifiers_columns = [\n",
    "        'id', 'datarun_id', 'hyperpartition_id', 'model_location',\n",
    "        'metrics_location', 'hyperparameter_values_64', 'cv_judgment_metric',\n",
    "        'test_judgment_metric', 'start_time', 'end_time', 'status', 'error_message',\n",
    "    ]   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = classifiers[classifiers_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datarun_id</th>\n",
       "      <td>68</td>\n",
       "      <td>145</td>\n",
       "      <td>155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hyperpartition_id</th>\n",
       "      <td>11532</td>\n",
       "      <td>24896</td>\n",
       "      <td>26555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_location</th>\n",
       "      <td>NaN</td>\n",
       "      <td>models/cf03ebc08c25d33ba76d5414345abfb6-bb5b76...</td>\n",
       "      <td>models/17307d3b00eb7718edf9d9617b9afe54-e3de60...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>metrics_location</th>\n",
       "      <td>NaN</td>\n",
       "      <td>metrics/cf03ebc08c25d33ba76d5414345abfb6-bb5b7...</td>\n",
       "      <td>metrics/17307d3b00eb7718edf9d9617b9afe54-e3de6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hyperparameter_values_64</th>\n",
       "      <td>NaN</td>\n",
       "      <td>function:classify_mlp;_scale:True;solver:sgd;l...</td>\n",
       "      <td>function:classify_sgd;loss:modified_huber;eta0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cv_judgment_metric</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.632857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_judgment_metric</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.645161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>start_time</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-08-18 14:46:52</td>\n",
       "      <td>2017-08-18 14:46:50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>end_time</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-08-18 14:46:55</td>\n",
       "      <td>2017-08-18 14:46:52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>status</th>\n",
       "      <td>errored</td>\n",
       "      <td>completed</td>\n",
       "      <td>completed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>error_message</th>\n",
       "      <td>Traceback (most recent call last):\\n  File \"wo...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                          0  \\\n",
       "id                                                                        1   \n",
       "datarun_id                                                               68   \n",
       "hyperpartition_id                                                     11532   \n",
       "model_location                                                          NaN   \n",
       "metrics_location                                                        NaN   \n",
       "hyperparameter_values_64                                                NaN   \n",
       "cv_judgment_metric                                                      NaN   \n",
       "test_judgment_metric                                                    NaN   \n",
       "start_time                                                              NaN   \n",
       "end_time                                                                NaN   \n",
       "status                                                              errored   \n",
       "error_message             Traceback (most recent call last):\\n  File \"wo...   \n",
       "\n",
       "                                                                          1  \\\n",
       "id                                                                        2   \n",
       "datarun_id                                                              145   \n",
       "hyperpartition_id                                                     24896   \n",
       "model_location            models/cf03ebc08c25d33ba76d5414345abfb6-bb5b76...   \n",
       "metrics_location          metrics/cf03ebc08c25d33ba76d5414345abfb6-bb5b7...   \n",
       "hyperparameter_values_64  function:classify_mlp;_scale:True;solver:sgd;l...   \n",
       "cv_judgment_metric                                                      0.1   \n",
       "test_judgment_metric                                                      0   \n",
       "start_time                                              2017-08-18 14:46:52   \n",
       "end_time                                                2017-08-18 14:46:55   \n",
       "status                                                            completed   \n",
       "error_message                                                           NaN   \n",
       "\n",
       "                                                                          2  \n",
       "id                                                                        3  \n",
       "datarun_id                                                              155  \n",
       "hyperpartition_id                                                     26555  \n",
       "model_location            models/17307d3b00eb7718edf9d9617b9afe54-e3de60...  \n",
       "metrics_location          metrics/17307d3b00eb7718edf9d9617b9afe54-e3de6...  \n",
       "hyperparameter_values_64  function:classify_sgd;loss:modified_huber;eta0...  \n",
       "cv_judgment_metric                                                 0.632857  \n",
       "test_judgment_metric                                               0.645161  \n",
       "start_time                                              2017-08-18 14:46:50  \n",
       "end_time                                                2017-08-18 14:46:52  \n",
       "status                                                            completed  \n",
       "error_message                                                           NaN  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifiers.head(3).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading file gp+bandit-search/csvs/new/classifiers.csv to S3 bucket s3.Bucket(name='atm-data-store')\n"
     ]
    }
   ],
   "source": [
    "to_csv(classifiers, 'classifiers.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
